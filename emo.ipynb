{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26fbea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f0eed8f23749b7bc31f86049bf8347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5e28effe244cf2b107d50eaa20bc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/768 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d68ca185e9b452ba4abb2c433d965b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ac0b11fa2a443190579bf0f61c3497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 15:16:00.460799: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-10 15:16:01.036602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedf369f428c442784826262be735b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritika22408/.local/lib/python3.8/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load EmoBERTa\n",
    "emo_model_name = \"nateraw/bert-base-uncased-emotion\"\n",
    "emo_tokenizer = AutoTokenizer.from_pretrained(emo_model_name)\n",
    "emo_model = AutoModelForSequenceClassification.from_pretrained(emo_model_name)\n",
    "emo_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ff2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion labels in EmoRoBERTa\n",
    "emo_labels = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
    "              'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust',\n",
    "              'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love',\n",
    "              'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse',\n",
    "              'sadness', 'surprise', 'neutral']\n",
    "\n",
    "def predict_emotion(text):\n",
    "    # Ensure the input is a string\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    inputs = emo_tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = emo_model(**inputs).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return emo_labels[predicted_class_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b15a1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_and_save_with_emotion(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for file in os.listdir(input_dir):\n",
    "        if file.endswith(\".csv\"):\n",
    "            path = os.path.join(input_dir, file)\n",
    "            df = pd.read_csv(path)\n",
    "\n",
    "            # Ensure the Emotion column is of object type so that strings can be assigned.\n",
    "            if 'Emotion' in df.columns:\n",
    "                df['Emotion'] = df['Emotion'].astype(object)\n",
    "            else:\n",
    "                df['Emotion'] = \"\"\n",
    "            \n",
    "            # Standardize the utterance for easier comparisons\n",
    "            df['Utterance_cleaned'] = df['Utterance'].str.lower().str.strip()\n",
    "\n",
    "            # Fill in missing or empty Emotion values using the emotion prediction function.\n",
    "            for idx, row in df.iterrows():\n",
    "                if pd.isna(row['Emotion']) or row['Emotion'] == \"\":\n",
    "                    # Skip rows with empty utterance (or handle as desired)\n",
    "                    if pd.isna(row['Utterance']) or row['Utterance'].strip() == \"\":\n",
    "                        continue\n",
    "                    if row['Utterance_cleaned'] not in ['summary', 'primary_topic', 'secondary_topic']:\n",
    "                        df.at[idx, 'Emotion'] = predict_emotion(row['Utterance'])\n",
    "\n",
    "            \n",
    "            # Optionally, you could drop the helper column after processing.\n",
    "            df.drop(columns=['Utterance_cleaned'], inplace=True)\n",
    "            \n",
    "            # Save the modified CSV to the output directory.\n",
    "            df.to_csv(os.path.join(output_dir, file), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d3c68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964520c6ebe74261871df7ec7ebb459f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enrich_and_save_with_emotion(\n",
    "    \"dataset/Train\", \n",
    "    \"dataset/Train_Emo\"\n",
    ")\n",
    "enrich_and_save_with_emotion(\n",
    "    \"dataset/Validation\", \n",
    "    \"dataset/Validation_Emo\"\n",
    ")\n",
    "enrich_and_save_with_emotion(\n",
    "    \"dataset/Test\", \n",
    "    \"dataset/Test_Emo\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
