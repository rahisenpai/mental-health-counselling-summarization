{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T18:22:08.614008Z",
     "iopub.status.busy": "2025-04-08T18:22:08.613796Z",
     "iopub.status.idle": "2025-04-08T18:22:23.398692Z",
     "shell.execute_reply": "2025-04-08T18:22:23.397669Z",
     "shell.execute_reply.started": "2025-04-08T18:22:08.613987Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/google-research/bleurt.git -q\n",
    "!pip install bert_score rouge-score evaluate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T18:22:23.399999Z",
     "iopub.status.busy": "2025-04-08T18:22:23.399662Z",
     "iopub.status.idle": "2025-04-08T18:22:58.589976Z",
     "shell.execute_reply": "2025-04-08T18:22:58.588864Z",
     "shell.execute_reply.started": "2025-04-08T18:22:23.399968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dca4b5ee19744c4a3784bb326dc0b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0b9f0dbed34ed29db11c8bed52502a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d44ff5e47264e88bd0bbdec61434838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dec2194468e4fb494fd3817055f6a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bffaa54a5c4551b32be4933d868fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80fbfdf2d08d416ab28fff4b26341318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4923bbb88642ae96deabb7ec0c03dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#initializing model and tokenizer\n",
    "model_name = \"google/pegasus-xsum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprcoessing dataset to find metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T18:24:01.814360Z",
     "iopub.status.busy": "2025-04-08T18:24:01.814075Z",
     "iopub.status.idle": "2025-04-08T18:24:01.820451Z",
     "shell.execute_reply": "2025-04-08T18:24:01.819487Z",
     "shell.execute_reply.started": "2025-04-08T18:24:01.814339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(path):\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset by reading all the csv files in the given path and\n",
    "    converts it into a list of dictionaries with the input text and the summary text.\n",
    "    \"\"\"\n",
    "    csv_files = [os.path.join(path, file) for file in os.listdir(path) if file.endswith(\".csv\")]\n",
    "    data = []\n",
    "\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        #extract the summary\n",
    "        df['Utterance_cleaned'] = df['Utterance'].str.lower().str.strip() # to handle \"summary \" and \"Summary\"\n",
    "        summary_row = df[df[\"Utterance_cleaned\"] == \"summary\"]\n",
    "        summary_text = summary_row.iloc[0, 1] if not summary_row.empty else \"\"\n",
    "\n",
    "        #filter out rows that are not actual utterances\n",
    "        dialogue_df = df[~df[\"Utterance_cleaned\"].isin([\"summary\", \"primary_topic\", \"secondary_topic\"])]\n",
    "\n",
    "        #drop inactive utterances\n",
    "        dialogue_df = dialogue_df[dialogue_df['Sub topic'] != 'inactive']\n",
    "\n",
    "        #concatenate utterances and format input\n",
    "        full_dialogue = \" \".join(dialogue_df[\"Utterance\"].dropna())\n",
    "\n",
    "        input_text = f\"summarize: {full_dialogue}\"\n",
    "        data.append({\"input\": input_text, \"summary\": summary_text})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T18:24:02.162323Z",
     "iopub.status.busy": "2025-04-08T18:24:02.161933Z",
     "iopub.status.idle": "2025-04-08T18:24:03.216980Z",
     "shell.execute_reply": "2025-04-08T18:24:03.215995Z",
     "shell.execute_reply.started": "2025-04-08T18:24:02.162290Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = preprocess_dataset(\"/kaggle/input/dataset/Train\")\n",
    "val_data = preprocess_dataset(\"/kaggle/input/dataset/Validation\")\n",
    "test_data = preprocess_dataset(\"/kaggle/input/dataset/Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T17:41:52.285715Z",
     "iopub.status.busy": "2025-04-08T17:41:52.285433Z",
     "iopub.status.idle": "2025-04-08T17:41:56.086056Z",
     "shell.execute_reply": "2025-04-08T17:41:56.085418Z",
     "shell.execute_reply.started": "2025-04-08T17:41:52.285688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "#making hugging face dataset instance to fine tune with trainer api\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "\n",
    "#create a dataset dictionary\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T17:41:56.087148Z",
     "iopub.status.busy": "2025-04-08T17:41:56.086884Z",
     "iopub.status.idle": "2025-04-08T17:41:56.599991Z",
     "shell.execute_reply": "2025-04-08T17:41:56.599027Z",
     "shell.execute_reply.started": "2025-04-08T17:41:56.087127Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4fcb18944b04d53b4d352dd6c5f2084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a104b396fa4e50a74ef05e857b5f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84fd1753747b40139238c717a735bad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset for fine tuning the model.\n",
    "    \"\"\"\n",
    "    model_inputs = tokenizer(examples[\"input\"], padding=\"longest\", truncation=True)\n",
    "    labels = tokenizer(examples[\"summary\"], padding=\"max_length\", truncation=True, max_length=150)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T17:41:56.601879Z",
     "iopub.status.busy": "2025-04-08T17:41:56.601626Z",
     "iopub.status.idle": "2025-04-08T18:03:22.383590Z",
     "shell.execute_reply": "2025-04-08T18:03:22.382653Z",
     "shell.execute_reply.started": "2025-04-08T17:41:56.601855Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='660' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [660/660 21:06, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.652900</td>\n",
       "      <td>5.334397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.018900</td>\n",
       "      <td>5.293077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.564700</td>\n",
       "      <td>5.227047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.657600</td>\n",
       "      <td>5.149861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.229200</td>\n",
       "      <td>5.047176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.857200</td>\n",
       "      <td>4.943526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.677500</td>\n",
       "      <td>4.855015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.176500</td>\n",
       "      <td>4.782526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.991800</td>\n",
       "      <td>4.707219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.536200</td>\n",
       "      <td>4.649623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.642300</td>\n",
       "      <td>4.599945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.513200</td>\n",
       "      <td>4.553056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.351500</td>\n",
       "      <td>4.517046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.560400</td>\n",
       "      <td>4.480505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.301400</td>\n",
       "      <td>4.449601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4.828400</td>\n",
       "      <td>4.425745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4.582200</td>\n",
       "      <td>4.410932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>4.430200</td>\n",
       "      <td>4.396585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>4.245900</td>\n",
       "      <td>4.395127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.393177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./pegasus-finetuned/tokenizer_config.json',\n",
       " './pegasus-finetuned/special_tokens_map.json',\n",
       " './pegasus-finetuned/spiece.model',\n",
       " './pegasus-finetuned/added_tokens.json',\n",
       " './pegasus-finetuned/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fine tuning the model with trainer api and save the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./pegasus-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"./pegasus-finetuned\")\n",
    "tokenizer.save_pretrained(\"./pegasus-finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T18:24:30.820657Z",
     "iopub.status.busy": "2025-04-08T18:24:30.820332Z",
     "iopub.status.idle": "2025-04-08T18:26:05.379058Z",
     "shell.execute_reply": "2025-04-08T18:26:05.378350Z",
     "shell.execute_reply.started": "2025-04-08T18:24:30.820631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/pegasus-finetuned\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/input/pegasus-finetuned\")\n",
    "model.to(device)\n",
    "\n",
    "for item in test_data:\n",
    "    input_text = item[\"input\"]\n",
    "\n",
    "    #tokenize input\n",
    "    input_ids = tokenizer(input_text, padding=\"longest\", return_tensors=\"pt\", truncation=True).input_ids.to(device)\n",
    "\n",
    "    #generate summary\n",
    "    summary_ids = model.generate(input_ids, max_length=150, num_beams=8, repetition_penalty=5.0, early_stopping=True)\n",
    "    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    #store the generated summary\n",
    "    item[\"generated_summary\"] = generated_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating BLEU score and BERT score on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T18:26:27.341704Z",
     "iopub.status.busy": "2025-04-08T18:26:27.341344Z",
     "iopub.status.idle": "2025-04-08T18:26:27.346012Z",
     "shell.execute_reply": "2025-04-08T18:26:27.345033Z",
     "shell.execute_reply.started": "2025-04-08T18:26:27.341672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "references = [] #list to store target summaries\n",
    "predictions = [] #list to store generated summaries\n",
    "\n",
    "for item in test_data:\n",
    "    references.append(item[\"summary\"])  #ground truth summaries\n",
    "    predictions.append(item[\"generated_summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T18:26:34.973535Z",
     "iopub.status.busy": "2025-04-08T18:26:34.973229Z",
     "iopub.status.idle": "2025-04-08T18:27:10.229488Z",
     "shell.execute_reply": "2025-04-08T18:27:10.228783Z",
     "shell.execute_reply.started": "2025-04-08T18:26:34.973507Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d573aa7e94f64a3d8e5a94ec0fd15453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e87663615454a13b8b0e351f78b3ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/405M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372d1fbd1cc94c7da5c2cdd7532b136c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5d22c451cc4403b83cf59ef233b261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a821a3b4fd8d45bbabec567806e37577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39d4ce5e8e74c80ab78480e8f2bec32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8be737438994963956e10dc47e8a1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2873a3a74eed4713afa62319f5c1c640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import evaluate\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "\n",
    "#Rogue score\n",
    "def compute_rouge(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        score = scorer.score(ref, pred)\n",
    "        scores['rouge1'].append(score['rouge1'].fmeasure)\n",
    "        scores['rouge2'].append(score['rouge2'].fmeasure)\n",
    "        scores['rougeL'].append(score['rougeL'].fmeasure)\n",
    "    return {key: sum(val)/len(val) for key, val in scores.items()}  # Averaging scores\n",
    "\n",
    "rouge_scores = compute_rouge(predictions, references)\n",
    "\n",
    "#BLEURT score\n",
    "bleurt = evaluate.load(\"bleurt\", config_name=\"bleurt-base-128\")\n",
    "results = bleurt.compute(predictions=predictions, references=references)\n",
    "avg_bleurt = sum(results[\"scores\"]) / len(results[\"scores\"])\n",
    "\n",
    "#BLEU score\n",
    "smoothie = SmoothingFunction().method4\n",
    "bleu_scores = [sentence_bleu(ref, pred.split(), smoothing_function=smoothie) for ref, pred in zip(references, predictions)]\n",
    "avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "#BERT score\n",
    "P, R, F1 = score(predictions, [ref[0] for ref in references], lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T18:27:10.230986Z",
     "iopub.status.busy": "2025-04-08T18:27:10.230751Z",
     "iopub.status.idle": "2025-04-08T18:27:10.238450Z",
     "shell.execute_reply": "2025-04-08T18:27:10.237651Z",
     "shell.execute_reply.started": "2025-04-08T18:27:10.230965Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rogue-1 Score: 29.07\n",
      "Rogue-2 Score: 9.09\n",
      "Rogue-L Score: 18.39\n",
      "BLEURT Score: -0.7210\n",
      "\n",
      "BLEU score: 11.39\n",
      "BERT score F1: 79.81\n",
      "BERT score Precision: 77.95\n",
      "BERT score Recall: 81.78\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rogue-1 Score: {rouge_scores['rouge1'] * 100:.2f}\")\n",
    "print(f\"Rogue-2 Score: {rouge_scores['rouge2'] * 100:.2f}\")\n",
    "print(f\"Rogue-L Score: {rouge_scores['rougeL'] * 100:.2f}\")\n",
    "print(f\"BLEURT Score: {avg_bleurt:.4f}\")\n",
    "print()\n",
    "print(f\"BLEU score: {avg_bleu * 100:.2f}\")\n",
    "print(f\"BERT score F1: {F1.mean().item() * 100:.2f}\")\n",
    "print(f\"BERT score Precision: {P.mean().item() * 100:.2f}\")\n",
    "print(f\"BERT score Recall: {R.mean().item() * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T18:27:10.239957Z",
     "iopub.status.busy": "2025-04-08T18:27:10.239755Z",
     "iopub.status.idle": "2025-04-08T18:27:10.554655Z",
     "shell.execute_reply": "2025-04-08T18:27:10.553845Z",
     "shell.execute_reply.started": "2025-04-08T18:27:10.239939Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original summary: The therapist examines the abdomen and other parts of the body. The therapist pulls down the eyelids and checks for anemia, then for scar signs. The therapist requests to perform shifting dullness test, full lymph retinopathy screen including accelerate and inguinal lymph nodes.\n",
      "\n",
      "Generated summary: The patient has a few other parts of their body that they would like to examine.\n"
     ]
    }
   ],
   "source": [
    "print('Original summary:', references[1])\n",
    "print()\n",
    "print('Generated summary:', predictions[1])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11755917,
     "datasetId": 6939705,
     "sourceId": 11330561,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
