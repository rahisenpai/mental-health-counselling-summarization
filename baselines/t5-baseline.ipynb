{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11164202,"sourceType":"datasetVersion","datasetId":6939705}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/google-research/bleurt.git -q\n!pip install bert_score rouge-score evaluate -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T16:42:39.252795Z","iopub.execute_input":"2025-04-08T16:42:39.254025Z","iopub.status.idle":"2025-04-08T16:42:59.894618Z","shell.execute_reply.started":"2025-04-08T16:42:39.253960Z","shell.execute_reply":"2025-04-08T16:42:59.893005Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\ntorch.manual_seed(42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n#initializing model and tokenizer\nmodel_name = \"t5-base\"\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T16:42:59.896609Z","iopub.execute_input":"2025-04-08T16:42:59.897259Z","iopub.status.idle":"2025-04-08T16:43:34.383937Z","shell.execute_reply.started":"2025-04-08T16:42:59.897207Z","shell.execute_reply":"2025-04-08T16:43:34.382713Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c133f3e4adc484a832231685e821609"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b5d398a640c49998a00b4a9df236867"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b07c247d6ff4a9299518645c1dbda38"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa77da6027f8455aa5a6ea7f1ad9124e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60cd10751fa547e5bf238a7664073984"}},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"## Preprcoessing dataset to find metrics","metadata":{}},{"cell_type":"code","source":"def preprocess_dataset(path):\n    \"\"\"\n    Preprocesses the dataset by reading all the csv files in the given path and\n    converts it into a list of dictionaries with the input text and the summary text.\n    \"\"\"\n    csv_files = [os.path.join(path, file) for file in os.listdir(path) if file.endswith(\".csv\")]\n    data = []\n\n    for file in csv_files:\n        df = pd.read_csv(file)\n\n        #extract the summary\n        df['Utterance_cleaned'] = df['Utterance'].str.lower().str.strip() # to handle \"summary \" and \"Summary\"\n        summary_row = df[df[\"Utterance_cleaned\"] == \"summary\"]\n        summary_text = summary_row.iloc[0, 1] if not summary_row.empty else \"\"\n\n        #filter out rows that are not actual utterances\n        dialogue_df = df[~df[\"Utterance_cleaned\"].isin([\"summary\", \"primary_topic\", \"secondary_topic\"])]\n\n        #drop inactive utterances\n        dialogue_df = dialogue_df[dialogue_df['Sub topic'] != 'inactive']\n\n        #concatenate utterances and format input\n        full_dialogue = \" \".join(dialogue_df[\"Utterance\"].dropna())\n\n        input_text = f\"summarize: {full_dialogue}\"\n        data.append({\"input\": input_text, \"summary\": summary_text})\n\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T16:43:47.404263Z","iopub.execute_input":"2025-04-08T16:43:47.404735Z","iopub.status.idle":"2025-04-08T16:43:47.413158Z","shell.execute_reply.started":"2025-04-08T16:43:47.404704Z","shell.execute_reply":"2025-04-08T16:43:47.411296Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_data = preprocess_dataset(\"/kaggle/input/nlp-dataset/dataset/Train\")\nval_data = preprocess_dataset(\"/kaggle/input/nlp-dataset/dataset/Validation\")\ntest_data = preprocess_dataset(\"/kaggle/input/nlp-dataset/dataset/Test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T16:43:49.466086Z","iopub.execute_input":"2025-04-08T16:43:49.466462Z","iopub.status.idle":"2025-04-08T16:43:52.146069Z","shell.execute_reply.started":"2025-04-08T16:43:49.466414Z","shell.execute_reply":"2025-04-08T16:43:52.145134Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Fine-tuning the model","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nfrom datasets import Dataset, DatasetDict\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n#making hugging face dataset instance to fine tune with trainer api\ntrain_dataset = Dataset.from_list(train_data)\nval_dataset = Dataset.from_list(val_data)\ntest_dataset = Dataset.from_list(test_data)\n\n#create a dataset dictionary\ndataset = DatasetDict({\n    \"train\": train_dataset,\n    \"validation\": val_dataset,\n    \"test\": test_dataset\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T16:43:56.906803Z","iopub.execute_input":"2025-04-08T16:43:56.907249Z","iopub.status.idle":"2025-04-08T16:44:00.343062Z","shell.execute_reply.started":"2025-04-08T16:43:56.907213Z","shell.execute_reply":"2025-04-08T16:44:00.341826Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def preprocess_function(examples):\n    \"\"\"\n    Preprocesses the dataset for fine tuning the model.\n    \"\"\"\n    model_inputs = tokenizer(examples[\"input\"], padding=\"max_length\", truncation=True, max_length=1024)\n    labels = tokenizer(examples[\"summary\"], padding=\"max_length\", truncation=True, max_length=150)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_dataset = dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T16:44:00.344613Z","iopub.execute_input":"2025-04-08T16:44:00.345004Z","iopub.status.idle":"2025-04-08T16:44:02.361166Z","shell.execute_reply.started":"2025-04-08T16:44:00.344967Z","shell.execute_reply":"2025-04-08T16:44:02.360161Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/131 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6115a0e19aa347328851645221fd24bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/21 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"824dc5cda0c745209b639159ce80497c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/39 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67cdeea2e9c740e791f228f4c0d88e33"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"#fine tuning the model with trainer api and save the model\ntraining_args = TrainingArguments(\n    output_dir=\"./t5-finetuned\",\n    eval_strategy=\"epoch\",\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    learning_rate=1e-5,\n    num_train_epochs=20,\n    weight_decay=0.01,\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"]\n)\n\ntrainer.train()\n\nmodel.save_pretrained(\"./t5-finetuned\")\ntokenizer.save_pretrained(\"./t5-finetuned\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:46:59.245439Z","iopub.execute_input":"2025-03-25T16:46:59.245674Z","iopub.status.idle":"2025-03-25T17:01:30.506578Z","shell.execute_reply.started":"2025-03-25T16:46:59.245641Z","shell.execute_reply":"2025-03-25T17:01:30.505604Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='660' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [660/660 14:25, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>7.218800</td>\n      <td>6.337772</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>5.083500</td>\n      <td>3.877070</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.293000</td>\n      <td>3.051157</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.591100</td>\n      <td>2.892324</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.820400</td>\n      <td>2.808407</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.572900</td>\n      <td>2.744962</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.403400</td>\n      <td>2.711519</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.414800</td>\n      <td>2.686369</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.171800</td>\n      <td>2.666864</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.328900</td>\n      <td>2.649522</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.235100</td>\n      <td>2.636713</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.441800</td>\n      <td>2.626068</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.343200</td>\n      <td>2.618792</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.142200</td>\n      <td>2.610201</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.342200</td>\n      <td>2.606859</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.045200</td>\n      <td>2.604444</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.993000</td>\n      <td>2.601782</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>2.152800</td>\n      <td>2.598446</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>2.217600</td>\n      <td>2.596837</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.125100</td>\n      <td>2.596140</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"('./t5-finetuned/tokenizer_config.json',\n './t5-finetuned/special_tokens_map.json',\n './t5-finetuned/spiece.model',\n './t5-finetuned/added_tokens.json')"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Summarizing the texts","metadata":{}},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(\"/kaggle/input/nlp-dataset/t5-finetuned\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"/kaggle/input/nlp-dataset/t5-finetuned\")\nmodel.to(device)\n\nfor item in test_data:\n    input_text = item[\"input\"]\n\n    #tokenize input\n    input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids.to(device)\n\n    #generate summary\n    summary_ids = model.generate(input_ids, max_length=150, num_beams=8, repetition_penalty=5.0, early_stopping=True)\n    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n    #store the generated summary\n    item[\"generated_summary\"] = generated_summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:27:36.188419Z","iopub.execute_input":"2025-03-25T17:27:36.188809Z","iopub.status.idle":"2025-03-25T17:30:05.872910Z","shell.execute_reply.started":"2025-03-25T17:27:36.188771Z","shell.execute_reply":"2025-03-25T17:30:05.872143Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Calculating BLEU score and BERT score on test set","metadata":{}},{"cell_type":"code","source":"references = [] #list to store target summaries\npredictions = [] #list to store generated summaries\n\nfor item in test_data:\n    references.append(item[\"summary\"])  #ground truth summaries\n    predictions.append(item[\"generated_summary\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:30:05.873902Z","iopub.execute_input":"2025-03-25T17:30:05.874250Z","iopub.status.idle":"2025-03-25T17:30:05.878731Z","shell.execute_reply.started":"2025-03-25T17:30:05.874216Z","shell.execute_reply":"2025-03-25T17:30:05.877944Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from bert_score import score\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nimport evaluate\nfrom rouge_score import rouge_scorer\n\n\n#Rogue score\ndef compute_rouge(predictions, references):\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n    for pred, ref in zip(predictions, references):\n        score = scorer.score(ref, pred)\n        scores['rouge1'].append(score['rouge1'].fmeasure)\n        scores['rouge2'].append(score['rouge2'].fmeasure)\n        scores['rougeL'].append(score['rougeL'].fmeasure)\n    return {key: sum(val)/len(val) for key, val in scores.items()}  # Averaging scores\n\nrouge_scores = compute_rouge(predictions, references)\n\n#BLEURT score\nbleurt = evaluate.load(\"bleurt\", config_name=\"bleurt-base-128\")\nresults = bleurt.compute(predictions=predictions, references=references)\navg_bleurt = sum(results[\"scores\"]) / len(results[\"scores\"])\n\n#BLEU score\nsmoothie = SmoothingFunction().method4\nbleu_scores = [sentence_bleu(ref, pred.split(), smoothing_function=smoothie) for ref, pred in zip(references, predictions)]\navg_bleu = sum(bleu_scores) / len(bleu_scores)\n\n#BERT score\nP, R, F1 = score(predictions, [ref[0] for ref in references], lang=\"en\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:30:05.880682Z","iopub.execute_input":"2025-03-25T17:30:05.880937Z","iopub.status.idle":"2025-03-25T17:30:35.650357Z","shell.execute_reply.started":"2025-03-25T17:30:05.880916Z","shell.execute_reply":"2025-03-25T17:30:35.649599Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"179294d6da514630adc005b90d0432b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afef5d0259d849498bf01007d4ac2663"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f73f7226b3884758ae0cf603dc93fb10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61c64d4d004d4cb5902514cb22eb2029"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53d420845fc84288b4f71f47842233a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6baf150ce73945108d53bbf78eac60c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb17c3d784c742e3b65f3c33647cf194"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b4f72ab5d37486ba24a7aa2767da608"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(f\"Rogue-1 Score: {rouge_scores['rouge1'] * 100:.2f}\")\nprint(f\"Rogue-2 Score: {rouge_scores['rouge2'] * 100:.2f}\")\nprint(f\"Rogue-L Score: {rouge_scores['rougeL'] * 100:.2f}\")\nprint(f\"BLEURT Score: {avg_bleurt:.4f}\")\nprint()\nprint(f\"BLEU score: {avg_bleu * 100:.2f}\")\nprint(f\"BERT score F1: {F1.mean().item() * 100:.2f}\")\nprint(f\"BERT score Precision: {P.mean().item() * 100:.2f}\")\nprint(f\"BERT score Recall: {R.mean().item() * 100:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:30:35.651752Z","iopub.execute_input":"2025-03-25T17:30:35.652237Z","iopub.status.idle":"2025-03-25T17:30:35.661523Z","shell.execute_reply.started":"2025-03-25T17:30:35.652167Z","shell.execute_reply":"2025-03-25T17:30:35.660576Z"}},"outputs":[{"name":"stdout","text":"Rogue-1 Score: 37.65\nRogue-2 Score: 12.91\nRogue-L Score: 22.14\nBLEURT Score: -0.6688\n\nBLEU score: 12.20\nBERT score F1: 79.41\nBERT score Precision: 77.56\nBERT score Recall: 81.36\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print('Original summary:', references[1])\nprint()\nprint('Generated summary:', predictions[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:32:02.518488Z","iopub.execute_input":"2025-03-25T17:32:02.518822Z","iopub.status.idle":"2025-03-25T17:32:02.524583Z","shell.execute_reply.started":"2025-03-25T17:32:02.518796Z","shell.execute_reply":"2025-03-25T17:32:02.523655Z"}},"outputs":[{"name":"stdout","text":"Original summary: The therapist examines the abdomen and other parts of the body. The therapist pulls down the eyelids and checks for anemia, then for scar signs. The therapist requests to perform shifting dullness test, full lymph retinopathy screen including accelerate and inguinal lymph nodes.\n\nGenerated summary: Dr. batata examines abdomen and other parts of body to look for evidence of anemia . \"it's gonna feel like it's live enough.\"\n","output_type":"stream"}],"execution_count":13}]}