{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26fbea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 13:32:02.668066: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-14 13:32:03.233975: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ritika22408/.local/lib/python3.8/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load EmoBERTa\n",
    "emo_model_name = \"nateraw/bert-base-uncased-emotion\"\n",
    "emo_tokenizer = AutoTokenizer.from_pretrained(emo_model_name)\n",
    "emo_model = AutoModelForSequenceClassification.from_pretrained(emo_model_name)\n",
    "emo_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ff2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion labels in EmoBERTa\n",
    "emo_labels = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
    "\n",
    "def predict_emotion(text):\n",
    "    # Ensure the input is a string\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    inputs = emo_tokenizer(text, return_tensors=\"pt\", truncation=True, truncation_strategy=\"only_first\")\n",
    "    with torch.no_grad():\n",
    "        logits = emo_model(**inputs).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return emo_labels[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b15a1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_and_save_with_emotion(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for file in os.listdir(input_dir):\n",
    "        if file.endswith(\".csv\"):\n",
    "            path = os.path.join(input_dir, file)\n",
    "            df = pd.read_csv(path)\n",
    "\n",
    "            # Ensure the Emotion column is of object type so that strings can be assigned.\n",
    "            if 'Emotion' in df.columns:\n",
    "                df['Emotion'] = df['Emotion'].astype(object)\n",
    "            else:\n",
    "                df['Emotion'] = \"\"\n",
    "            \n",
    "            # Create a helper column for normalized utterance content\n",
    "            df['Utterance_cleaned'] = df['Utterance'].str.lower().str.strip()\n",
    "\n",
    "            # Iterate through the conversation (row by row)\n",
    "            for idx, row in df.iterrows():\n",
    "                # If Emotion is missing or empty, we'll fill it\n",
    "                if pd.isna(row['Emotion']) or row['Emotion'] == \"\":\n",
    "                    # Skip rows with empty utterance\n",
    "                    if pd.isna(row['Utterance']) or row['Utterance'].strip() == \"\":\n",
    "                        continue\n",
    "                    # If the row isn't one of the special markers, proceed\n",
    "                    if row['Utterance_cleaned'] not in ['summary', 'primary_topic', 'secondary_topic']:\n",
    "                        # Concatenate all utterances from the start to the current row as conversation history.\n",
    "                        conversation_so_far = \" \".join(df.loc[:idx, \"Utterance\"].astype(str).tolist())\n",
    "                        # Predict emotion using the conversation history\n",
    "                        df.at[idx, 'Emotion'] = predict_emotion(conversation_so_far)\n",
    "            \n",
    "            # Drop the helper column if desired.\n",
    "            df.drop(columns=['Utterance_cleaned'], inplace=True)\n",
    "            \n",
    "            # Save the enriched CSV to the output directory.\n",
    "            df.to_csv(os.path.join(output_dir, file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d3c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_and_save_with_emotion(\n",
    "    \"dataset/Train\", \n",
    "    \"dataset/Train_Emo\"\n",
    ")\n",
    "enrich_and_save_with_emotion(\n",
    "    \"dataset/Validation\", \n",
    "    \"dataset/Validation_Emo\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eab583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_and_save_with_emotion(\n",
    "    \"dataset/Test\", \n",
    "    \"dataset/Test_Emo\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
