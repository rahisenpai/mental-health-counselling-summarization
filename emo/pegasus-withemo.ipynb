{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11392248,"sourceType":"datasetVersion","datasetId":7134569}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/google-research/bleurt.git -q\n!pip install bert_score rouge-score evaluate -q\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:20:14.935500Z","iopub.execute_input":"2025-04-13T20:20:14.935777Z","iopub.status.idle":"2025-04-13T20:21:50.804987Z","shell.execute_reply.started":"2025-04-13T20:20:14.935747Z","shell.execute_reply":"2025-04-13T20:21:50.803979Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntorch.manual_seed(42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n#initializing model and tokenizer\nmodel_name = \"google/pegasus-xsum\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:21:55.825069Z","iopub.execute_input":"2025-04-13T20:21:55.825351Z","iopub.status.idle":"2025-04-13T20:22:37.736648Z","shell.execute_reply.started":"2025-04-13T20:21:55.825325Z","shell.execute_reply":"2025-04-13T20:22:37.734050Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"463dbd20e62b43d8940d54763115b118"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f579f8c0fb324cbfb53defeece9efc29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1e9fe84bf2c4b009cfdb500125c2168"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23177576d37e4b629c189285b9acb020"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fc6c53a864747e2841913c277185edb"}},"metadata":{}},{"name":"stderr","text":"2025-04-13 20:22:10.047645: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744575730.294065      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744575730.364163      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3db01a52c0f94a02bda5b0ef09639a02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4fedaea6ffd4c65b70c16f303e46a9f"}},"metadata":{}},{"name":"stderr","text":"Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"959e5b8b8f3d4efd8c327f516ef7d27c"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"def preprocess_dataset(path):\n    \"\"\"\n    Preprocesses the dataset by reading all the csv files in the given path and\n    converts it into a list of dictionaries with the input text (now including emotion tags)\n    and the summary text.\n    \"\"\"\n    csv_files = [os.path.join(path, file) for file in os.listdir(path) if file.endswith(\".csv\")]\n    data = []\n\n    for file in csv_files:\n        df = pd.read_csv(file)\n\n        # Create a helper column for the cleaned utterances\n        df['Utterance_cleaned'] = df['Utterance'].str.lower().str.strip()\n        summary_row = df[df[\"Utterance_cleaned\"] == \"summary\"]\n        summary_text = summary_row.iloc[0, 1] if not summary_row.empty else \"\"\n        \n        # Filter out rows that are not actual utterances\n        dialogue_df = df[~df[\"Utterance_cleaned\"].isin([\"summary\", \"primary_topic\", \"secondary_topic\"])]\n\n        # Drop inactive utterances\n        dialogue_df = dialogue_df[dialogue_df['Sub topic'] != 'inactive']\n\n        # Incorporate the emotion value into each utterance.\n        # For example, prepend the emotion in square brackets.\n        dialogue_df[\"Emotion_Tagged\"] = \"[\" + dialogue_df[\"Emotion\"].astype(str) + \"] \" + dialogue_df[\"Utterance\"]\n\n        # Concatenate the emotion-tagged utterances\n        full_dialogue = \" \".join(dialogue_df[\"Emotion_Tagged\"].dropna())\n\n        # Format the input\n        input_text = f\"summarize: {full_dialogue}\"\n        data.append({\"input\": input_text, \"summary\": summary_text})\n\n    return data\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:23:12.279542Z","iopub.execute_input":"2025-04-13T20:23:12.280179Z","iopub.status.idle":"2025-04-13T20:23:12.286872Z","shell.execute_reply.started":"2025-04-13T20:23:12.280156Z","shell.execute_reply":"2025-04-13T20:23:12.286051Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Update paths to point to the datasets with emotion annotations\ntrain_data = preprocess_dataset(\"/kaggle/input/mental-health-counselling-summarization/dataset/Train_Emo\")\nval_data = preprocess_dataset(\"/kaggle/input/mental-health-counselling-summarization/dataset/Validation_Emo\")\ntest_data = preprocess_dataset(\"/kaggle/input/mental-health-counselling-summarization/dataset/Test_Emo\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:23:16.567222Z","iopub.execute_input":"2025-04-13T20:23:16.567782Z","iopub.status.idle":"2025-04-13T20:23:17.962281Z","shell.execute_reply.started":"2025-04-13T20:23:16.567757Z","shell.execute_reply":"2025-04-13T20:23:17.961659Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nfrom datasets import Dataset, DatasetDict\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n#making hugging face dataset instance to fine tune with trainer api\ntrain_dataset = Dataset.from_list(train_data)\nval_dataset = Dataset.from_list(val_data)\ntest_dataset = Dataset.from_list(test_data)\n\n#create a dataset dictionary\ndataset = DatasetDict({\n    \"train\": train_dataset,\n    \"validation\": val_dataset,\n    \"test\": test_dataset\n})\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:23:21.631445Z","iopub.execute_input":"2025-04-13T20:23:21.631775Z","iopub.status.idle":"2025-04-13T20:23:24.301957Z","shell.execute_reply.started":"2025-04-13T20:23:21.631753Z","shell.execute_reply":"2025-04-13T20:23:24.301133Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def preprocess_function(examples):\n    \"\"\"\n    Preprocesses the dataset for fine tuning the model.\n    \"\"\"\n    model_inputs = tokenizer(examples[\"input\"], padding=\"longest\", truncation=True)\n    labels = tokenizer(examples[\"summary\"], padding=\"max_length\", truncation=True, max_length=150)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_dataset = dataset.map(preprocess_function, batched=True)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:23:29.059979Z","iopub.execute_input":"2025-04-13T20:23:29.060589Z","iopub.status.idle":"2025-04-13T20:23:29.651417Z","shell.execute_reply.started":"2025-04-13T20:23:29.060561Z","shell.execute_reply":"2025-04-13T20:23:29.650597Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/131 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"653e2757885f4c2ead99f7554cc3ac42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/21 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22d64e32c284406c9931ac093ae107ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/39 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8caa23054b4f43c79f035add131de69b"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"#fine tuning the model with trainer api and save the model\ntraining_args = TrainingArguments(\n    output_dir=\"./pegasus-withemo-finetuned\",\n    eval_strategy=\"epoch\",\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    learning_rate=1e-5,\n    num_train_epochs=20,\n    weight_decay=0.01,\n    warmup_steps=500,\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"]\n)\n\ntrainer.train()\n\nmodel.save_pretrained(\"./pegasus-withemo-finetuned\")\ntokenizer.save_pretrained(\"./pegasus-withemo-finetuned\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:23:36.977927Z","iopub.execute_input":"2025-04-13T20:23:36.978773Z","iopub.status.idle":"2025-04-13T20:46:26.163479Z","shell.execute_reply.started":"2025-04-13T20:23:36.978736Z","shell.execute_reply":"2025-04-13T20:46:26.162638Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='660' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [660/660 22:29, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>6.668500</td>\n      <td>5.332132</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6.027500</td>\n      <td>5.290236</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5.568400</td>\n      <td>5.221765</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5.651100</td>\n      <td>5.140434</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>5.301900</td>\n      <td>5.049303</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>5.858400</td>\n      <td>4.947917</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>4.697900</td>\n      <td>4.852045</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>5.194800</td>\n      <td>4.781155</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>5.043500</td>\n      <td>4.710469</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>4.578600</td>\n      <td>4.654868</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>4.697900</td>\n      <td>4.605365</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>4.544200</td>\n      <td>4.565512</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>4.366400</td>\n      <td>4.531243</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>4.641300</td>\n      <td>4.499381</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>4.338200</td>\n      <td>4.470360</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>4.878000</td>\n      <td>4.448604</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>4.610600</td>\n      <td>4.435126</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>4.466800</td>\n      <td>4.421767</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>4.266900</td>\n      <td>4.415986</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>4.728300</td>\n      <td>4.413631</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"('./pegasus-withemo-finetuned/tokenizer_config.json',\n './pegasus-withemo-finetuned/special_tokens_map.json',\n './pegasus-withemo-finetuned/spiece.model',\n './pegasus-withemo-finetuned/added_tokens.json',\n './pegasus-withemo-finetuned/tokenizer.json')"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Load the fine-tuned model for testing\nmodel_path = \"/kaggle/working/pegasus-withemo-finetuned\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_path)\nmodel.to(device)\n\nfor item in test_data:\n    input_text = item[\"input\"]\n\n    #tokenize input\n    input_ids = tokenizer(input_text, padding=\"longest\", return_tensors=\"pt\", truncation=True).input_ids.to(device)\n\n    #generate summary\n    summary_ids = model.generate(input_ids, max_length=150, num_beams=8, repetition_penalty=5.0, early_stopping=True)\n    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n    #store the generated summary\n    item[\"generated_summary\"] = generated_summary\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:48:04.810994Z","iopub.execute_input":"2025-04-13T20:48:04.811278Z","iopub.status.idle":"2025-04-13T20:49:36.102421Z","shell.execute_reply.started":"2025-04-13T20:48:04.811257Z","shell.execute_reply":"2025-04-13T20:49:36.101518Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"references = [] #list to store target summaries\npredictions = [] #list to store generated summaries\n\nfor item in test_data:\n    references.append(item[\"summary\"])  #ground truth summaries\n    predictions.append(item[\"generated_summary\"])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:50:31.763528Z","iopub.execute_input":"2025-04-13T20:50:31.763806Z","iopub.status.idle":"2025-04-13T20:50:31.767854Z","shell.execute_reply.started":"2025-04-13T20:50:31.763787Z","shell.execute_reply":"2025-04-13T20:50:31.767237Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from bert_score import score\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nimport evaluate\nfrom rouge_score import rouge_scorer\n\n\n#Rogue score\ndef compute_rouge(predictions, references):\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n    for pred, ref in zip(predictions, references):\n        score = scorer.score(ref, pred)\n        scores['rouge1'].append(score['rouge1'].fmeasure)\n        scores['rouge2'].append(score['rouge2'].fmeasure)\n        scores['rougeL'].append(score['rougeL'].fmeasure)\n    return {key: sum(val)/len(val) for key, val in scores.items()}  # Averaging scores\n\nrouge_scores = compute_rouge(predictions, references)\n\n#BLEURT score\nbleurt = evaluate.load(\"bleurt\", config_name=\"bleurt-base-128\")\nresults = bleurt.compute(predictions=predictions, references=references)\navg_bleurt = sum(results[\"scores\"]) / len(results[\"scores\"])\n\n#BLEU score\nsmoothie = SmoothingFunction().method4\nbleu_scores = [sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie) for ref, pred in zip(references, predictions)]\navg_bleu = sum(bleu_scores) / len(bleu_scores)\n\n#BERT score\nP, R, F1 = score(predictions, references, lang=\"en\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:50:35.045721Z","iopub.execute_input":"2025-04-13T20:50:35.045993Z","iopub.status.idle":"2025-04-13T20:51:13.242237Z","shell.execute_reply.started":"2025-04-13T20:50:35.045972Z","shell.execute_reply":"2025-04-13T20:51:13.241501Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3016f5b1ff9463a8ee34733556c3b5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce705c094e954ca99b71c8fc0681261f"}},"metadata":{}},{"name":"stderr","text":"I0000 00:00:1744577447.831213      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1686 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1744577447.831847      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 7098 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20144723540f41c7b651b0a36446cd56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a1ea46ab5f6421b88defeee1837da16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63debc8eddbd490bb00983f054415ed6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9bd95f88fc94997a817641f74808b38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f86204f0bca4a8baf76f0827002d92b"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1020105b664146cfbeceaff58901412e"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(f\"Rogue-1 Score: {rouge_scores['rouge1'] * 100:.2f}\")\nprint(f\"Rogue-2 Score: {rouge_scores['rouge2'] * 100:.2f}\")\nprint(f\"Rogue-L Score: {rouge_scores['rougeL'] * 100:.2f}\")\nprint(f\"BLEURT Score: {avg_bleurt:.4f}\")\nprint()\nprint(f\"BLEU score: {avg_bleu * 100:.2f}\")\nprint(f\"BERT score F1: {F1.mean().item() * 100:.2f}\")\nprint(f\"BERT score Precision: {P.mean().item() * 100:.2f}\")\nprint(f\"BERT score Recall: {R.mean().item() * 100:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:51:51.943103Z","iopub.execute_input":"2025-04-13T20:51:51.943448Z","iopub.status.idle":"2025-04-13T20:51:51.951372Z","shell.execute_reply.started":"2025-04-13T20:51:51.943413Z","shell.execute_reply":"2025-04-13T20:51:51.950467Z"}},"outputs":[{"name":"stdout","text":"Rogue-1 Score: 29.42\nRogue-2 Score: 9.10\nRogue-L Score: 18.18\nBLEURT Score: -0.6747\n\nBLEU score: 2.16\nBERT score F1: 85.49\nBERT score Precision: 86.74\nBERT score Recall: 84.32\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print('Original summary:', references[1])\nprint()\nprint('Generated summary:', predictions[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T20:52:00.420822Z","iopub.execute_input":"2025-04-13T20:52:00.421597Z","iopub.status.idle":"2025-04-13T20:52:00.425770Z","shell.execute_reply.started":"2025-04-13T20:52:00.421573Z","shell.execute_reply":"2025-04-13T20:52:00.425005Z"}},"outputs":[{"name":"stdout","text":"Original summary: The therapist examines the abdomen and other parts of the body. The therapist pulls down the eyelids and checks for anemia, then for scar signs. The therapist requests to perform shifting dullness test, full lymph retinopathy screen including accelerate and inguinal lymph nodes.\n\nGenerated summary: The patient's doctor asks the patient to take their gun down.\n","output_type":"stream"}],"execution_count":15}]}