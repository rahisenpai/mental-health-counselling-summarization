{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-14T10:24:03.310683Z",
     "iopub.status.busy": "2025-04-14T10:24:03.310522Z",
     "iopub.status.idle": "2025-04-14T10:25:32.676974Z",
     "shell.execute_reply": "2025-04-14T10:25:32.676219Z",
     "shell.execute_reply.started": "2025-04-14T10:24:03.310667Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/google-research/bleurt.git -q\n",
    "!pip install bert_score rouge-score evaluate -q\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T10:25:57.476240Z",
     "iopub.status.busy": "2025-04-14T10:25:57.475958Z",
     "iopub.status.idle": "2025-04-14T10:26:41.336563Z",
     "shell.execute_reply": "2025-04-14T10:26:41.335451Z",
     "shell.execute_reply.started": "2025-04-14T10:25:57.476213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 10:26:10.552901: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744626370.762600      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744626370.822878      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce9f93b401f4eb7ade5b85c79aca857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35f1622e4d646c18f1cebc7f2e90204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8203e3dbd8442e4b7b30f3b11cd579b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617934c16409449daa673edf7bf7bf06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b67c0aaa2a4ad2aeacac63783ab143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef0c95dce714077856335f6acc2ae5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e684d838713e4d95a67b5f9b3e204b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2a57ffacb642d3bbcd0247ae2bed8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#initializing model and tokenizer\n",
    "model_name = \"google/pegasus-xsum\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# use below normally also\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprcoessing dataset to find metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T10:27:00.576882Z",
     "iopub.status.busy": "2025-04-14T10:27:00.576290Z",
     "iopub.status.idle": "2025-04-14T10:27:00.583523Z",
     "shell.execute_reply": "2025-04-14T10:27:00.582655Z",
     "shell.execute_reply.started": "2025-04-14T10:27:00.576860Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(path):\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset by reading all the csv files in the given path and\n",
    "    converts it into a list of dictionaries with the input text (now including emotion tags)\n",
    "    and the summary text.\n",
    "    \"\"\"\n",
    "    csv_files = [os.path.join(path, file) for file in os.listdir(path) if file.endswith(\".csv\")]\n",
    "    data = []\n",
    "\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # Create a helper column for the cleaned utterances\n",
    "        df['Utterance_cleaned'] = df['Utterance'].str.lower().str.strip()\n",
    "        summary_row = df[df[\"Utterance_cleaned\"] == \"summary\"]\n",
    "        summary_text = summary_row.iloc[0, 1] if not summary_row.empty else \"\"\n",
    "        \n",
    "        # Filter out rows that are not actual utterances\n",
    "        dialogue_df = df[~df[\"Utterance_cleaned\"].isin([\"summary\", \"primary_topic\", \"secondary_topic\"])]\n",
    "\n",
    "        # Drop inactive utterances\n",
    "        dialogue_df = dialogue_df[dialogue_df['Sub topic'] != 'inactive']\n",
    "\n",
    "        # Incorporate the emotion value into each utterance.\n",
    "        # For example, prepend the emotion in square brackets.\n",
    "        dialogue_df[\"Emotion_Tagged\"] = \"[\" + dialogue_df[\"Emotion\"].astype(str) + \"] \" + dialogue_df[\"Utterance\"]\n",
    "\n",
    "        # Concatenate the emotion-tagged utterances\n",
    "        full_dialogue = \" \".join(dialogue_df[\"Emotion_Tagged\"].dropna())\n",
    "\n",
    "        # Format the input\n",
    "        input_text = f\"summarize: {full_dialogue}\"\n",
    "        data.append({\"input\": input_text, \"summary\": summary_text})\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T10:27:04.013761Z",
     "iopub.status.busy": "2025-04-14T10:27:04.013486Z",
     "iopub.status.idle": "2025-04-14T10:27:05.398424Z",
     "shell.execute_reply": "2025-04-14T10:27:05.397522Z",
     "shell.execute_reply.started": "2025-04-14T10:27:04.013741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Update paths to point to the datasets with emotion annotations\n",
    "train_data = preprocess_dataset(\"/kaggle/input/project/mental-health-counselling-summarization/dataset/Train_Emo\")\n",
    "val_data = preprocess_dataset(\"/kaggle/input/project/mental-health-counselling-summarization/dataset/Validation_Emo\")\n",
    "test_data = preprocess_dataset(\"/kaggle/input/project/mental-health-counselling-summarization/dataset/Test_Emo\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T10:27:12.152072Z",
     "iopub.status.busy": "2025-04-14T10:27:12.151308Z",
     "iopub.status.idle": "2025-04-14T10:27:15.024583Z",
     "shell.execute_reply": "2025-04-14T10:27:15.024048Z",
     "shell.execute_reply.started": "2025-04-14T10:27:12.152043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "#making hugging face dataset instance to fine tune with trainer api\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "\n",
    "#create a dataset dictionary\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T10:27:33.633515Z",
     "iopub.status.busy": "2025-04-14T10:27:33.632930Z",
     "iopub.status.idle": "2025-04-14T10:27:35.058863Z",
     "shell.execute_reply": "2025-04-14T10:27:35.058148Z",
     "shell.execute_reply.started": "2025-04-14T10:27:33.633490Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161b28e237844be389cff0e9158cfcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515c8a6786ea4cc196de58ff1673d4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f7e90f8bee4cb68c58902bce3c8d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset for fine tuning the model.\n",
    "    \"\"\"\n",
    "    model_inputs = tokenizer(examples[\"input\"], padding=\"longest\", truncation=True)\n",
    "    labels = tokenizer(examples[\"summary\"], padding=\"max_length\", truncation=True, max_length=150)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T11:33:06.970778Z",
     "iopub.status.busy": "2025-04-14T11:33:06.970491Z",
     "iopub.status.idle": "2025-04-14T11:55:50.309168Z",
     "shell.execute_reply": "2025-04-14T11:55:50.308523Z",
     "shell.execute_reply.started": "2025-04-14T11:33:06.970758Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='660' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [660/660 22:33, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.127600</td>\n",
       "      <td>3.011381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.220500</td>\n",
       "      <td>3.002050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.151400</td>\n",
       "      <td>3.026817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.013700</td>\n",
       "      <td>3.066074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.261300</td>\n",
       "      <td>3.044156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.117900</td>\n",
       "      <td>3.133889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.057100</td>\n",
       "      <td>3.142179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.949800</td>\n",
       "      <td>3.227339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>3.294977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.912300</td>\n",
       "      <td>3.317235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.851300</td>\n",
       "      <td>3.380467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.865900</td>\n",
       "      <td>3.519987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>3.651289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>3.684620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.631800</td>\n",
       "      <td>3.933790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.499400</td>\n",
       "      <td>3.689214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>4.000681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.568200</td>\n",
       "      <td>3.944381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>4.176203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.529400</td>\n",
       "      <td>4.060125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./pegasus-withemo-finetuned/tokenizer_config.json',\n",
       " './pegasus-withemo-finetuned/special_tokens_map.json',\n",
       " './pegasus-withemo-finetuned/spiece.model',\n",
       " './pegasus-withemo-finetuned/added_tokens.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fine tuning the model with trainer api and save the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./pegasus-withemo-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"./pegasus-withemo-finetuned\")\n",
    "tokenizer.save_pretrained(\"./pegasus-withemo-finetuned\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T11:57:15.261988Z",
     "iopub.status.busy": "2025-04-14T11:57:15.261666Z",
     "iopub.status.idle": "2025-04-14T11:59:06.024452Z",
     "shell.execute_reply": "2025-04-14T11:59:06.023867Z",
     "shell.execute_reply.started": "2025-04-14T11:57:15.261966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the fine-tuned model for testing\n",
    "model_path = \"/kaggle/working/pegasus-withemo-finetuned\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_path)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "\n",
    "for item in test_data:\n",
    "    input_text = item[\"input\"]\n",
    "\n",
    "    #tokenize input\n",
    "    input_ids = tokenizer(input_text, padding=\"longest\", return_tensors=\"pt\", truncation=True).input_ids.to(device)\n",
    "\n",
    "    #generate summary\n",
    "    summary_ids = model.generate(input_ids, max_length=150, num_beams=8, repetition_penalty=5.0, early_stopping=True)\n",
    "    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    #store the generated summary\n",
    "    item[\"generated_summary\"] = generated_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating BLEU score and BERT score on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T12:01:11.986192Z",
     "iopub.status.busy": "2025-04-14T12:01:11.985597Z",
     "iopub.status.idle": "2025-04-14T12:01:11.989917Z",
     "shell.execute_reply": "2025-04-14T12:01:11.989323Z",
     "shell.execute_reply.started": "2025-04-14T12:01:11.986169Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "references = [] #list to store target summaries\n",
    "predictions = [] #list to store generated summaries\n",
    "\n",
    "for item in test_data:\n",
    "    references.append(item[\"summary\"])  #ground truth summaries\n",
    "    predictions.append(item[\"generated_summary\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T12:01:14.371134Z",
     "iopub.status.busy": "2025-04-14T12:01:14.370476Z",
     "iopub.status.idle": "2025-04-14T12:01:28.176703Z",
     "shell.execute_reply": "2025-04-14T12:01:28.176145Z",
     "shell.execute_reply.started": "2025-04-14T12:01:14.371111Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import evaluate\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "\n",
    "#Rogue score\n",
    "def compute_rouge(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        score = scorer.score(ref, pred)\n",
    "        scores['rouge1'].append(score['rouge1'].fmeasure)\n",
    "        scores['rouge2'].append(score['rouge2'].fmeasure)\n",
    "        scores['rougeL'].append(score['rougeL'].fmeasure)\n",
    "    return {key: sum(val)/len(val) for key, val in scores.items()}  # Averaging scores\n",
    "\n",
    "rouge_scores = compute_rouge(predictions, references)\n",
    "\n",
    "#BLEURT score\n",
    "bleurt = evaluate.load(\"bleurt\", config_name=\"bleurt-base-128\")\n",
    "results = bleurt.compute(predictions=predictions, references=references)\n",
    "avg_bleurt = sum(results[\"scores\"]) / len(results[\"scores\"])\n",
    "\n",
    "#BLEU score\n",
    "smoothie = SmoothingFunction().method4\n",
    "bleu_scores = [sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie) for ref, pred in zip(references, predictions)]\n",
    "avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "#BERT score\n",
    "P, R, F1 = score(predictions, references, lang=\"en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T12:04:02.031318Z",
     "iopub.status.busy": "2025-04-14T12:04:02.030651Z",
     "iopub.status.idle": "2025-04-14T12:04:02.036554Z",
     "shell.execute_reply": "2025-04-14T12:04:02.035962Z",
     "shell.execute_reply.started": "2025-04-14T12:04:02.031294Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rogue-1 Score: 38.02\n",
      "Rogue-2 Score: 12.68\n",
      "Rogue-L Score: 22.09\n",
      "BLEURT Score: -0.5782\n",
      "\n",
      "BLEU score: 5.05\n",
      "BERT score F1: 86.65\n",
      "BERT score Precision: 87.58\n",
      "BERT score Recall: 85.79\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rogue-1 Score: {rouge_scores['rouge1'] * 100:.2f}\")\n",
    "print(f\"Rogue-2 Score: {rouge_scores['rouge2'] * 100:.2f}\")\n",
    "print(f\"Rogue-L Score: {rouge_scores['rougeL'] * 100:.2f}\")\n",
    "print(f\"BLEURT Score: {avg_bleurt:.4f}\")\n",
    "print()\n",
    "print(f\"BLEU score: {avg_bleu * 100:.2f}\")\n",
    "print(f\"BERT score F1: {F1.mean().item() * 100:.2f}\")\n",
    "print(f\"BERT score Precision: {P.mean().item() * 100:.2f}\")\n",
    "print(f\"BERT score Recall: {R.mean().item() * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T12:05:55.181620Z",
     "iopub.status.busy": "2025-04-14T12:05:55.181010Z",
     "iopub.status.idle": "2025-04-14T12:05:55.185461Z",
     "shell.execute_reply": "2025-04-14T12:05:55.184588Z",
     "shell.execute_reply.started": "2025-04-14T12:05:55.181597Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original summary: The patient's emotional inventory of stress, worry and anxiety is rated three by the patient. The patient feels slightly better than before. The therapist suggests two tasks. One is to give a self talk in the morning when the automatic clock comes up, and next is to note down the automatic thoughts like feelings of anxiety when it occurs in the day. The therapist suggests to maintain a journal so that they can work on the patient's adaptive responses. The therapist assures to set up an appointment for next week and assures patient of their strong ability to overcome this. \n",
      "\n",
      "Generated summary: The patient is asked to take a emotional inventory of their stress and worry and anxiety and scale it, as the therapist scales it. The patient feels closer to three now feeling more hopeful and not feeling like when they came in. The patient is asked to apply self talk in the morning to make a plan for the week. One homework step is to cultivate an awareness about the automatic thoughts that leads to worry. The second step is to try to recover the feelings of worry.\n"
     ]
    }
   ],
   "source": [
    "print('Original summary:', references[31])\n",
    "print()\n",
    "print('Generated summary:', predictions[31])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7134569,
     "sourceId": 11392248,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7140007,
     "sourceId": 11400023,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
