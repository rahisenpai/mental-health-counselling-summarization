{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-11T16:18:55.241191Z",
     "iopub.status.busy": "2025-04-11T16:18:55.240924Z",
     "iopub.status.idle": "2025-04-11T16:19:06.447305Z",
     "shell.execute_reply": "2025-04-11T16:19:06.446525Z",
     "shell.execute_reply.started": "2025-04-11T16:18:55.241170Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/google-research/bleurt.git -q\n",
    "!pip install bert_score rouge-score evaluate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T16:19:06.448441Z",
     "iopub.status.busy": "2025-04-11T16:19:06.448228Z",
     "iopub.status.idle": "2025-04-11T16:19:32.706694Z",
     "shell.execute_reply": "2025-04-11T16:19:32.705957Z",
     "shell.execute_reply.started": "2025-04-11T16:19:06.448418Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 16:19:20.964526: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744388361.191746      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744388361.254903      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T16:19:32.708672Z",
     "iopub.status.busy": "2025-04-11T16:19:32.708210Z",
     "iopub.status.idle": "2025-04-11T16:19:38.102493Z",
     "shell.execute_reply": "2025-04-11T16:19:38.101722Z",
     "shell.execute_reply.started": "2025-04-11T16:19:32.708654Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d801d596dda948f49790c52d8cdce3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de51e240f214ae4b82b843b471e117e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425e3370bac64d5db6ddbaa4b5c44947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0657216aa906469dae4f2858378773ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bafe402dccda48c1ac79b5251669fc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#initializing model and tokenizer\n",
    "model_name = \"t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T16:19:38.103745Z",
     "iopub.status.busy": "2025-04-11T16:19:38.103390Z",
     "iopub.status.idle": "2025-04-11T16:19:38.111304Z",
     "shell.execute_reply": "2025-04-11T16:19:38.110536Z",
     "shell.execute_reply.started": "2025-04-11T16:19:38.103719Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(path):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset by reading all CSV files in the given path.\n",
    "    For each conversation (CSV file), the function constructs an input string\n",
    "    that concatenates each utterance preceded by its emotion token. \n",
    "    This way, each line is contextualized with the emotional cues from previous lines.\n",
    "    \"\"\"\n",
    "    csv_files = [os.path.join(path, file) for file in os.listdir(path) if file.endswith(\".csv\")]\n",
    "    data = []\n",
    "    \n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Ensure that the CSV file has been enriched with an Emotion column\n",
    "        # and clean the utterance strings for consistency.\n",
    "        df['Utterance_cleaned'] = df['Utterance'].str.lower().str.strip()\n",
    "        \n",
    "        # Extract the summary row (if available)\n",
    "        summary_row = df[df[\"Utterance_cleaned\"] == \"summary\"]\n",
    "        summary_text = summary_row.iloc[0, 1] if not summary_row.empty else \"\"\n",
    "        \n",
    "        # Filter out rows that are not actual utterances (e.g., summary, primary_topic, secondary_topic)\n",
    "        dialogue_df = df[~df[\"Utterance_cleaned\"].isin([\"summary\", \"primary_topic\", \"secondary_topic\"])]\n",
    "        # Drop rows labeled as inactive\n",
    "        dialogue_df = dialogue_df[dialogue_df['Sub topic'] != 'inactive']\n",
    "        \n",
    "        # Construct conversation history:\n",
    "        # For each utterance, prepend its emotion token, and accumulate all lines.\n",
    "        conversation_context = \"\"\n",
    "        for idx, row in dialogue_df.iterrows():\n",
    "            # Get the current emotion and utterance.\n",
    "            # We assume that the CSV was enriched earlier so that the \"Emotion\" column is non-empty.\n",
    "            current_emotion = row[\"Emotion\"]\n",
    "            current_utterance = row[\"Utterance\"]\n",
    "            # Format the line as \"[Emotion] utterance\"\n",
    "            current_line = f\"[{current_emotion}] {current_utterance}\"\n",
    "            # Append this line to the conversation context.\n",
    "            conversation_context += \" \" + current_line\n",
    "        \n",
    "        # Build the final input text. The model will see the full conversation (with emotion tokens).\n",
    "        input_text = f\"summarize: {conversation_context.strip()}\"\n",
    "        data.append({\"input\": input_text, \"summary\": summary_text})\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T16:19:38.112756Z",
     "iopub.status.busy": "2025-04-11T16:19:38.112110Z",
     "iopub.status.idle": "2025-04-11T16:19:39.428757Z",
     "shell.execute_reply": "2025-04-11T16:19:39.428000Z",
     "shell.execute_reply.started": "2025-04-11T16:19:38.112732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = preprocess_dataset(\"/kaggle/input/memo-kdd/Train_Emo\")\n",
    "val_data = preprocess_dataset(\"/kaggle/input/memo-kdd/Validation_Emo\")\n",
    "test_data = preprocess_dataset(\"/kaggle/input/memo-kdd/Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T16:19:39.429945Z",
     "iopub.status.busy": "2025-04-11T16:19:39.429653Z",
     "iopub.status.idle": "2025-04-11T16:19:42.008270Z",
     "shell.execute_reply": "2025-04-11T16:19:42.007688Z",
     "shell.execute_reply.started": "2025-04-11T16:19:39.429924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "#making hugging face dataset instance to fine tune with trainer api\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "\n",
    "#create a dataset dictionary\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T16:19:42.009267Z",
     "iopub.status.busy": "2025-04-11T16:19:42.008982Z",
     "iopub.status.idle": "2025-04-11T16:19:43.424247Z",
     "shell.execute_reply": "2025-04-11T16:19:43.423241Z",
     "shell.execute_reply.started": "2025-04-11T16:19:42.009236Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a265d27a1f47298f91891fac941ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/131 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa8d81a0be24dc6829211b278a2f695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5231de8b14ba484fa058542f77ed8432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset for fine tuning the model.\n",
    "    \"\"\"\n",
    "    model_inputs = tokenizer(examples[\"input\"], padding=\"max_length\", truncation=True, max_length=1024)\n",
    "    labels = tokenizer(examples[\"summary\"], padding=\"max_length\", truncation=True, max_length=150)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T16:19:43.425811Z",
     "iopub.status.busy": "2025-04-11T16:19:43.425417Z",
     "iopub.status.idle": "2025-04-11T16:33:51.034722Z",
     "shell.execute_reply": "2025-04-11T16:33:51.033924Z",
     "shell.execute_reply.started": "2025-04-11T16:19:43.425759Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='660' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [660/660 14:01, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.134400</td>\n",
       "      <td>6.241673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.940900</td>\n",
       "      <td>3.761084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.224600</td>\n",
       "      <td>3.065937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.610100</td>\n",
       "      <td>2.918926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.861700</td>\n",
       "      <td>2.827606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.603200</td>\n",
       "      <td>2.769051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.442600</td>\n",
       "      <td>2.734866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.454200</td>\n",
       "      <td>2.708006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.197500</td>\n",
       "      <td>2.685897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.348600</td>\n",
       "      <td>2.667094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.276100</td>\n",
       "      <td>2.656765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.457600</td>\n",
       "      <td>2.645963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.392300</td>\n",
       "      <td>2.636455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.180800</td>\n",
       "      <td>2.629381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.386400</td>\n",
       "      <td>2.625277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.096400</td>\n",
       "      <td>2.623767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.031300</td>\n",
       "      <td>2.619006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.182300</td>\n",
       "      <td>2.616596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.278700</td>\n",
       "      <td>2.615360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.141600</td>\n",
       "      <td>2.614600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./t5-finetuned/tokenizer_config.json',\n",
       " './t5-finetuned/special_tokens_map.json',\n",
       " './t5-finetuned/spiece.model',\n",
       " './t5-finetuned/added_tokens.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fine tuning the model with trainer api and save the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.001,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"./t5-finetuned\")\n",
    "tokenizer.save_pretrained(\"./t5-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T16:33:51.038439Z",
     "iopub.status.busy": "2025-04-11T16:33:51.038206Z",
     "iopub.status.idle": "2025-04-11T16:36:38.516232Z",
     "shell.execute_reply": "2025-04-11T16:36:38.515669Z",
     "shell.execute_reply.started": "2025-04-11T16:33:51.038421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_path = \"/kaggle/working/t5-finetuned\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "\n",
    "for item in test_data:\n",
    "    input_text = item[\"input\"]\n",
    "\n",
    "    #tokenize input\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "\n",
    "    #generate summary\n",
    "    summary_ids = model.generate(input_ids, max_length=150, num_beams=8, repetition_penalty=5.0, early_stopping=True)\n",
    "    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    #store the generated summary\n",
    "    item[\"generated_summary\"] = generated_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T16:42:36.679029Z",
     "iopub.status.busy": "2025-04-11T16:42:36.678375Z",
     "iopub.status.idle": "2025-04-11T16:42:36.682972Z",
     "shell.execute_reply": "2025-04-11T16:42:36.682249Z",
     "shell.execute_reply.started": "2025-04-11T16:42:36.679005Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "references = [] #list to store target summaries\n",
    "predictions = [] #list to store generated summaries\n",
    "\n",
    "for item in test_data:\n",
    "    references.append(item[\"summary\"])  #ground truth summaries\n",
    "    predictions.append(item[\"generated_summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T16:42:39.314778Z",
     "iopub.status.busy": "2025-04-11T16:42:39.314533Z",
     "iopub.status.idle": "2025-04-11T16:43:16.847966Z",
     "shell.execute_reply": "2025-04-11T16:43:16.847161Z",
     "shell.execute_reply.started": "2025-04-11T16:42:39.314762Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2ac7be04874211b336c8ec96b75afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6a812e7a9643c48a5e99a4f0a2596a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/405M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744389770.414519      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5354 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1744389770.415174      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 7378 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29daa6153c2b4bacb0778a39c5c01581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f90536d3cad4ca096ca9a43e6237c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72ba4dd3b7b4a35a50cf4a4d037ec1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3bbdbcf49b4d4397def19c6299a35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36ac856e5cf43a095f63bd547b9d91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e9c94d5f1447c8a78697d1a735455e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import evaluate\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "\n",
    "#Rogue score\n",
    "def compute_rouge(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        score = scorer.score(ref, pred)\n",
    "        scores['rouge1'].append(score['rouge1'].fmeasure)\n",
    "        scores['rouge2'].append(score['rouge2'].fmeasure)\n",
    "        scores['rougeL'].append(score['rougeL'].fmeasure)\n",
    "    return {key: sum(val)/len(val) for key, val in scores.items()}  # Averaging scores\n",
    "\n",
    "rouge_scores = compute_rouge(predictions, references)\n",
    "\n",
    "#BLEURT score\n",
    "bleurt = evaluate.load(\"bleurt\", config_name=\"bleurt-base-128\")\n",
    "results = bleurt.compute(predictions=predictions, references=references)\n",
    "avg_bleurt = sum(results[\"scores\"]) / len(results[\"scores\"])\n",
    "\n",
    "#BLEU score\n",
    "smoothie = SmoothingFunction().method4\n",
    "bleu_scores = [sentence_bleu(ref, pred.split(), smoothing_function=smoothie) for ref, pred in zip(references, predictions)]\n",
    "avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "#BERT score\n",
    "P, R, F1 = score(predictions, [ref[0] for ref in references], lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T16:43:16.849636Z",
     "iopub.status.busy": "2025-04-11T16:43:16.849324Z",
     "iopub.status.idle": "2025-04-11T16:43:16.858352Z",
     "shell.execute_reply": "2025-04-11T16:43:16.857714Z",
     "shell.execute_reply.started": "2025-04-11T16:43:16.849612Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rogue-1 Score: 31.46\n",
      "Rogue-2 Score: 9.99\n",
      "Rogue-L Score: 19.46\n",
      "BLEURT Score: -0.8224\n",
      "\n",
      "BLEU score: 0.39\n",
      "BERT score F1: 75.63\n",
      "BERT score Precision: 73.81\n",
      "BERT score Recall: 77.55\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rogue-1 Score: {rouge_scores['rouge1'] * 100:.2f}\")\n",
    "print(f\"Rogue-2 Score: {rouge_scores['rouge2'] * 100:.2f}\")\n",
    "print(f\"Rogue-L Score: {rouge_scores['rougeL'] * 100:.2f}\")\n",
    "print(f\"BLEURT Score: {avg_bleurt:.4f}\")\n",
    "print()\n",
    "print(f\"BLEU score: {avg_bleu * 100:.2f}\")\n",
    "print(f\"BERT score F1: {F1.mean().item() * 100:.2f}\")\n",
    "print(f\"BERT score Precision: {P.mean().item() * 100:.2f}\")\n",
    "print(f\"BERT score Recall: {R.mean().item() * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T16:43:16.859538Z",
     "iopub.status.busy": "2025-04-11T16:43:16.859108Z",
     "iopub.status.idle": "2025-04-11T16:43:16.881447Z",
     "shell.execute_reply": "2025-04-11T16:43:16.880438Z",
     "shell.execute_reply.started": "2025-04-11T16:43:16.859514Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original summary: The therapist examines the abdomen and other parts of the body. The therapist pulls down the eyelids and checks for anemia, then for scar signs. The therapist requests to perform shifting dullness test, full lymph retinopathy screen including accelerate and inguinal lymph nodes.\n",
      "\n",
      "Generated summary: Dr. batata examines patient's abdomen and other parts of body . doctor pulls down on eyelids looking for any evidence of anemia.\n"
     ]
    }
   ],
   "source": [
    "print('Original summary:', references[1])\n",
    "print()\n",
    "print('Generated summary:', predictions[1])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7105903,
     "sourceId": 11360008,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
